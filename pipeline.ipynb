{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyPDF2 import PdfReader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "\n",
    "pinecone_api_key =  \"ebfd4dc6-ce8b-4516-a1b0-220fd6700bf7\"\n",
    "pinecone_index = \"pdfchat\"\n",
    "pinecone_namespace = \"pdf_ask\"\n",
    "api_key = \"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\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "os.environ[\"PINECONE_API_KEY\"] = pinecone_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chunks_from_pdf(pdf_path):\n",
    "    reader = PdfReader(pdf_path)\n",
    "    splitter = RecursiveCharacterTextSplitter()\n",
    "    chunks = []\n",
    "    for page in reader.pages:\n",
    "        text = page.extract_text()\n",
    "        chunks.extend(splitter.split_text(text))\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder = OpenAIEmbeddings(openai_api_key=api_key,model=\"text-embedding-3-large\",dimensions=3072)\n",
    "model = ChatOpenAI(openai_api_key=api_key,model=\"gpt-3.5-turbo\")\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello! I'm just a computer program, so I don't have feelings, but I'm here and ready to help you with any questions or tasks you have. How can I assist you today?\", response_metadata={'token_usage': {'completion_tokens': 40, 'prompt_tokens': 13, 'total_tokens': 53}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': 'fp_b28b39ffa8', 'finish_reason': 'stop', 'logprobs': None}, id='run-a9f225d9-fc5d-41fa-8ef9-13d2f4b98597-0')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke(\"Hello, how are you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"Ptk.pdf\"\n",
    "texts = get_chunks_from_pdf(file_name)\n",
    "metadata = [{\"file_name\": file_name,\"chunk_id\":idx} for idx in range(len(texts))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "store = PineconeVectorStore.from_texts(texts,\n",
    "                                       embedding=embedder,\n",
    "                                       metadatas=metadata,\n",
    "                                       index_name=pinecone_index,\n",
    "                                       namespace=pinecone_namespace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "store = FAISS.from_texts(texts, embedding=embedder, metadatas=metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "\n",
    "memory = ConversationBufferWindowMemory(max_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chain():\n",
    "     prompt_template = \"\"\"\n",
    "     Answer the question as detailed as possible from the provided context, make sure to provide all the details, if the answer is not in\n",
    "     provided context just say, \"answer is not available in the context\", don't provide the wrong answer\\n\\n\n",
    "     You get the user's chat history along with the context and question, if the user asks about a previous question, you can refer to the chat history\\n\\n\n",
    "     Users's chat history: \\n{chat_history}\\n\n",
    "     Context:\\n {context}?\\n\n",
    "     Question: \\n{question}\\n\n",
    "\n",
    "     Answer:\n",
    "     \"\"\"\n",
    "\n",
    "     prompt = PromptTemplate(template=prompt_template, input_variables=[\"context\", \"question\",\"chat_history\"])\n",
    "     chain = prompt |  model\n",
    "     return chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answer(prompt):\n",
    "     chain = get_chain()\n",
    "     docs = store.similarity_search(prompt,k=3)\n",
    "     context = \" \".join([doc.page_content for doc in docs])\n",
    "     answer = chain.invoke({\"context\":context,\n",
    "                           \"question\":prompt,\n",
    "                           \"chat_history\":memory.load_memory_variables({})}).content\n",
    "     memory.save_context({\"input\":prompt},{\"output\":answer}) \n",
    "     return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The user\\'s previous question was: \"Mi minősül kereskedelmi forgalomban való szerzésnek?\" (What constitutes acquisition in commercial circulation?)'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#prompt = \"Mi minősül kereskedelmi forgalomban való szerzésnek?\"\n",
    "prompt = \"What was my previous question?\"\n",
    "get_answer(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: Mi minősül kereskedelmi forgalomban való szerzésnek?\\nAI: A termék kereskedelmi forgalomban való szerzése akkor történik, amikor az adott termék megfelel a gyártó által történt forgalomba hozatalakor hatályos minőségi követelményeknek, vagy ha rendelkezik a gyártó által adott leírásban szereplő tulajdonságokkal. Ez azt jelenti, hogy amikor egy terméket vásárolunk, és az megfelel ezeknek a követelményeknek, akkor azt kereskedelmi forgalomban szerezzük be.\\nHuman: What was my previous question?\\nAI: The user\\'s previous question was: \"Mi minősül kereskedelmi forgalomban való szerzésnek?\" (What constitutes acquisition in commercial circulation?)'}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatbot_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
